{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38758df9",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/jesusvillota/CSS_DataScience_2025/blob/main/Session3/3_2_RAG_IV_Full_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeabd5b4",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 880px; margin: 20px auto 22px; padding: 0px; border-radius: 18px; border: 1px solid #e5e7eb; background: linear-gradient(180deg, #ffffff 0%, #f9fafb 100%); box-shadow: 0 8px 26px rgba(0,0,0,0.06); overflow: hidden;\">\n",
    "\n",
    "  <!-- Banner Header -->\n",
    "  <div style=\"padding: 34px 32px 14px; text-align: center; line-height: 1.38;\">\n",
    "    <div style=\"font-size: 13px; letter-spacing: 0.14em; text-transform: uppercase; color: #6b7280; font-weight: bold; margin-bottom: 5px;\">\n",
    "      Session #2\n",
    "    </div>\n",
    "    <div style=\"font-size: 29px; font-weight: 800; color: #14276c; margin-bottom: 4px;\">\n",
    "      RAG with LangChain\n",
    "    </div>\n",
    "    <div style=\"font-size: 29px; font-weight: 800; color: #14276c; margin-bottom: 4px;\">\n",
    "      Part V: Chat with your data\n",
    "    </div>\n",
    "    <div style=\"font-size: 16.5px; color: #374151; font-style: italic; margin-bottom: 0;\">\n",
    "      Data Science for Economics: Mastering Unstructured Data\n",
    "    </div>\n",
    "  </div>\n",
    "\n",
    "  <!-- Logo Section -->\n",
    "  <div style=\"background: none; text-align: center; margin: 30px 0 10px;\">\n",
    "    <img src=\"https://www.cemfi.es/images/Logo-Azul.png\" alt=\"CEMFI Logo\" style=\"width: 158px; filter: drop-shadow(0 2px 12px rgba(56,84,156,0.05)); margin-bottom: 0;\">\n",
    "  </div>\n",
    "\n",
    "  <!-- Name -->\n",
    "  <div style=\"font-family: 'Times New Roman', Times, serif; color: #38549c; text-align: center; font-size: 1.22em; font-weight: bold; margin-bottom: 0px;\">\n",
    "    Jesus Villota Miranda Â© 2025\n",
    "  </div>\n",
    "\n",
    "  <!-- Contact info -->\n",
    "  <div style=\"font-family: 'Times New Roman', Times, serif; color: #38549c; text-align: center; font-size: 1em; margin-top: 7px; margin-bottom: 20px;\">\n",
    "    <a href=\"mailto:jesus.villota@cemfi.edu.es\" style=\"color: #38549c; text-decoration: none; margin-right:8px;\" title=\"Email\">\n",
    "      <!-- Email logo -->\n",
    "      <!-- <img src=\"https://cdn-icons-png.flaticon.com/512/11679/11679732.png\" alt=\"Email\" style=\"width:18px; vertical-align:middle; margin-right:5px;\"> -->\n",
    "      jesus.villota@cemfi.edu.es\n",
    "    </a>\n",
    "    <span style=\"color:#9fa7bd;\">|</span>\n",
    "    <a href=\"https://www.linkedin.com/in/jesusvillotamiranda/\" target=\"_blank\" style=\"color: #38549c; text-decoration: none; margin-left:7px;\" title=\"LinkedIn\">\n",
    "      <!-- LinkedIn logo -->\n",
    "      <!-- <img src=\"https://1.bp.blogspot.com/-onvhHUdW1Us/YI52e9j4eKI/AAAAAAAAE4c/6s9wzOpIDYcAo4YmTX1Qg51OlwMFmilFACLcBGAsYHQ/s1600/Logo%2BLinkedin.png\" alt=\"LinkedIn\" style=\"width:17px; vertical-align:middle; margin-right:5px;\"> -->\n",
    "      LinkedIn\n",
    "    </a>\n",
    "  </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c3862c",
   "metadata": {},
   "source": [
    "**IMPORTANT**: **Are you running this notebook in Google Colab?**\n",
    "\n",
    "- If so, please make sure that in the cell below `running_in_colab` is set to `True`\n",
    "\n",
    "- And, of course,  make sure to **run the cell**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3974b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_in_colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "470e4618",
   "metadata": {},
   "outputs": [],
   "source": [
    "if running_in_colab: \n",
    "    ! pip install langchain_huggingface openai pypdf\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    folder_dir = '/content/drive/My Drive/docs/'\n",
    "else: \n",
    "    folder_dir = 'docs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef480fe",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Recall the overall workflow for retrieval augmented generation (RAG):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fa2dab",
   "metadata": {},
   "source": [
    "![](images/rag_pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8825752",
   "metadata": {},
   "source": [
    "The final step in RAG is to merge the retrieved documents and the original query to produce a final answer. \n",
    "This process is intermediated by an LLM, which sees both your prompt and the retrieved documents as context and then generates an informed response.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"images/RAG.png\" alt=\"RAG Final Step\" width=\"320\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3c9e7e",
   "metadata": {},
   "source": [
    "In this notebook we will complete the full RAG pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec929ccd",
   "metadata": {},
   "source": [
    "# **RAG Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0779ed6a",
   "metadata": {},
   "source": [
    "1) **Document Loading**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d849626",
   "metadata": {},
   "source": [
    "- Let's load some example PDFs. \n",
    "- For this illustration, we will use the transcripts from the first three lectures of the CS229 Machine Learning course (Stanford).\n",
    "- https://see.stanford.edu/Course/CS229\n",
    "- Make sure to download the pdfs to your Drive to be able to load the documents (I uploaded them to `Session3/docs`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b997cff1",
   "metadata": {
    "height": 166,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load PDF\n",
    "loaders = [\n",
    "    PyPDFLoader(folder_dir + \"MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(folder_dir + \"MachineLearning-Lecture02.pdf\"),\n",
    "    PyPDFLoader(folder_dir + \"MachineLearning-Lecture03.pdf\")\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4743c4",
   "metadata": {},
   "source": [
    "2) **Splitting**\n",
    "\n",
    "We use the RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73225ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cce27e",
   "metadata": {},
   "source": [
    "3) **Embeddings**\n",
    "\n",
    "- Here I give you the option to do it with a free open-source model from HuggingFace, or with the more sophisticated OpenAI embeddings.\n",
    "- Note that, to use the OpenAI embeddings, you need need an OPENAI_API_KEY and credit in your OpenAI account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "763cd6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if running_in_colab:\n",
    "    try:\n",
    "        from google.colab import secrets\n",
    "        api_key = secrets[\"OPENAI_API_KEY\"]\n",
    "    except Exception as e:\n",
    "        print(\"Could not retrieve OPENAI_API_KEY from Colab secrets:\", e)\n",
    "        api_key = None\n",
    "else:\n",
    "    import os\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ccbea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "use_free_embeddings = False\n",
    "\n",
    "if use_free_embeddings:\n",
    "    from langchain_huggingface import HuggingFaceEmbeddings\n",
    "    embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "else:\n",
    "    # You need an OPENAI_API_KEY and credit in your OpenAI account\n",
    "    embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a106b060",
   "metadata": {},
   "source": [
    "4) **Vectorstore**\n",
    "- As we saw in the previous notebook, we can store our embeddings in a vectorstore \n",
    "- We use Chroma, but there are other alternatives you can explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9977d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "persist_directory = 'chroma_vectordb/'\n",
    "\n",
    "import os\n",
    "os.makedirs(persist_directory, exist_ok=True)\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7524d36",
   "metadata": {},
   "source": [
    "5) **Define the user question**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac6058bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Is probability a class topic?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94cbba3",
   "metadata": {},
   "source": [
    "6) **Context retrieval**\n",
    "\n",
    "- This is the context that is retrieved when we call `retriever=vectordb.as_retriever()` on the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fc56058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================[ ðŸ“„ Relevant Chunk 1 ]========================================\n",
      "of this class will not be very programming intensive, although we will do some \n",
      "programming, mostly in either MATLAB or Octave. I'll say a bit more about that later.  \n",
      "I also assume familiarity with basic probability and statistics. So most undergraduate \n",
      "statistics class, like Stat 116 taught here at Stanford, will be more than enough. I'm gonna \n",
      "assume all of you know what random variables are, that all of you know what expectation \n",
      "is, what a variance or a random variable is. And in case of some of you, it's been a while \n",
      "since you've seen some of this material. At some of the discussion sections, we'll actually \n",
      "go over some of the prerequisites, sort of as a refresher course under prerequisite class. \n",
      "I'll say a bit more about that later as well.  \n",
      "Lastly, I also assume familiarity with basic linear algebra. And again, most undergraduate \n",
      "linear algebra courses are more than enough. So if you've taken courses like Math 51, \n",
      "103, Math 113 or CS205 at Stanford, that would be more than enough. Basically, I'm \n",
      "gonna assume that all of you know what matrixes and vectors are, that you know how to \n",
      "multiply matrices and vectors and multiply matrix and matrices, that you know what a \n",
      "matrix inverse is. If you know what an eigenvector of a matrix is, that'd be even better. \n",
      "But if you don't quite know or if you're not quite sure, that's fine, too. We'll go over it in \n",
      "the review sections.\n",
      "\n",
      "========================================[ ðŸ“„ Relevant Chunk 2 ]========================================\n",
      "Instructor (Andrew Ng):Yeah, yeah. I mean, youâ€™re asking about overfitting, whether \n",
      "this is a good model. I think letâ€™s â€“ the thingâ€™s youâ€™re mentioning are maybe deeper \n",
      "questions about learning algorithms that weâ€™ll just come back to later, so donâ€™t really \n",
      "want to get into that right now. Any more questions? Okay.  \n",
      "So this endows linear regression with a probabilistic interpretation. Iâ€™m actually going to \n",
      "use this probabil â€“ use this, sort of, probabilistic interpretation in order to derive our next \n",
      "learning algorithm, which will be our first classification algorithm. Okay? So youâ€™ll recall \n",
      "that I said that regression problems are where the variable Y that youâ€™re trying to predict \n",
      "is continuous values. Now Iâ€™m actually gonna talk about our first classification problem, \n",
      "where the value Y youâ€™re trying to predict will be discreet value. You can take on only a \n",
      "small number of discrete values and in this case Iâ€™ll talk about binding classification \n",
      "where Y takes on only two values, right? So you come up with classification problems if \n",
      "youâ€™re trying to do, say, a medical diagnosis and try to decide based on some features that \n",
      "the patient has a disease or does not have a disease. Or if in the housing example, maybe \n",
      "youâ€™re trying to decide will this house sell in the next six months or not and the answer is \n",
      "either yes or no. Itâ€™ll either be sold in the next six months or it wonâ€™t be. Other standing\n",
      "\n",
      "========================================[ ðŸ“„ Relevant Chunk 3 ]========================================\n",
      "statistics for a while or maybe algebra, we'll go over those in the discussion sections as a \n",
      "refresher for those of you that want one.  \n",
      "Later in this quarter, we'll also use the discussion sections to go over extensions for the \n",
      "material that I'm teaching in the main lectures. So machine learning is a huge field, and \n",
      "there are a few extensions that we really want to teach but didn't have time in the main \n",
      "lectures for.\n",
      "\n",
      "========================================[ ðŸ“„ Relevant Chunk 4 ]========================================\n",
      "come back to this again. Any questions about this? Actually, let me clean up another \n",
      "couple of boards and then Iâ€™ll see what questions you have.  \n",
      "Okay. Any questions? Yeah?  \n",
      "Student:You are, I think here you try to measure the likelihood of your nice of theta by a \n",
      "fraction of error, but I think itâ€™s that you measure because it depends on the family of \n",
      "theta too, for example. If you have a lot of parameters [inaudible] or fitting in?\n",
      "\n",
      "========================================[ ðŸ“„ Relevant Chunk 5 ]========================================\n",
      "But if you don't quite know or if you're not quite sure, that's fine, too. We'll go over it in \n",
      "the review sections.  \n",
      "So there are a couple more logistical things I should deal with in this class. One is that, as \n",
      "most of you know, CS229 is a televised class. And in fact, I guess many of you are \n",
      "probably watching this at home on TV, so I'm gonna say hi to our home viewers.  \n",
      "So earlier this year, I approached SCPD, which televises these classes, about trying to \n",
      "make a small number of Stanford classes publicly available or posting the videos on the \n",
      "web. And so this year, Stanford is actually starting a small pilot program in which we'll \n",
      "post videos of a small number of classes online, so on the Internet in a way that makes it \n",
      "publicly accessible to everyone. I'm very excited about that because machine learning in \n",
      "school, let's get the word out there.  \n",
      "One of the consequences of this is that â€” let's see â€” so videos  or pictures of the students \n",
      "in this classroom will not be posted online, so your images â€” so don't worry about being \n",
      "by seeing your own face appear on YouTube one day. But the microphones may pick up \n",
      "your voices, so I guess the consequence of that is that because microphones may pick up \n",
      "your voices, no matter how irritated you are at me, don't yell out swear words in the \n",
      "middle of class, but because there won't be video you can safely sit there and make faces \n",
      "at me, and that won't show, okay?\n"
     ]
    }
   ],
   "source": [
    "docs = vectordb.similarity_search(question,k=5)\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    print(\"\\n\" + \"=\"*40 + f\"[ ðŸ“„ Relevant Chunk {i+1} ]\" + \"=\"*40)\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e0c13b",
   "metadata": {},
   "source": [
    "7) **Pass the template and context to the LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a11701f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/7j25pgqd5z3dh647gtb8vmbw0000gn/T/ipykernel_93990/879426986.py:3: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model_name=llm_name, temperature=0)\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm_name = \"gpt-3.5-turbo\"\n",
    "llm = ChatOpenAI(model_name=llm_name, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b37519f",
   "metadata": {
    "height": 166,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "# Build prompt\n",
    "template = \"\"\"\n",
    "            Use the following pieces of context to answer the question at the end. \\\n",
    "            If you don't know the answer, just say that you don't know, don't try to make up an answer. \\\n",
    "            Use three sentences maximum. Keep the answer as concise as possible. \\\n",
    "            Always say \"thanks for asking!\" at the end of the answer. \\\n",
    "            Context: {context} \\\n",
    "            Question: {question} \\\n",
    "            Helpful Answer:\n",
    "            \"\"\"\n",
    "            \n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714fbe0f",
   "metadata": {},
   "source": [
    "8) **Build the QA prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcb5817c",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "# Run chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6813803e",
   "metadata": {},
   "source": [
    "9) **Build the RetrievalQA chain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3a21b52",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/7j25pgqd5z3dh647gtb8vmbw0000gn/T/ipykernel_93990/4094420968.py:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"query\": question})\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5872efa9",
   "metadata": {},
   "source": [
    "10) **Run the chain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ab4c517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Is probability a class topic?',\n",
       " 'result': 'Based on the context provided, probability is a topic covered in the class, as the instructor assumes familiarity with basic probability and statistics. Probability is used in the class to provide a probabilistic interpretation for linear regression and to derive the first classification algorithm. Thanks for asking!',\n",
       " 'source_documents': [Document(metadata={'title': '', 'page': 4, 'page_label': '5', 'moddate': '2008-07-11T11:25:23-07:00', 'total_pages': 22, 'creator': 'PScript5.dll Version 5.2.2', 'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'source': 'docs/MachineLearning-Lecture01.pdf', 'creationdate': '2008-07-11T11:25:23-07:00', 'author': ''}, page_content=\"of this class will not be very programming intensive, although we will do some \\nprogramming, mostly in either MATLAB or Octave. I'll say a bit more about that later.  \\nI also assume familiarity with basic probability and statistics. So most undergraduate \\nstatistics class, like Stat 116 taught here at Stanford, will be more than enough. I'm gonna \\nassume all of you know what random variables are, that all of you know what expectation \\nis, what a variance or a random variable is. And in case of some of you, it's been a while \\nsince you've seen some of this material. At some of the discussion sections, we'll actually \\ngo over some of the prerequisites, sort of as a refresher course under prerequisite class. \\nI'll say a bit more about that later as well.  \\nLastly, I also assume familiarity with basic linear algebra. And again, most undergraduate \\nlinear algebra courses are more than enough. So if you've taken courses like Math 51, \\n103, Math 113 or CS205 at Stanford, that would be more than enough. Basically, I'm \\ngonna assume that all of you know what matrixes and vectors are, that you know how to \\nmultiply matrices and vectors and multiply matrix and matrices, that you know what a \\nmatrix inverse is. If you know what an eigenvector of a matrix is, that'd be even better. \\nBut if you don't quite know or if you're not quite sure, that's fine, too. We'll go over it in \\nthe review sections.\"),\n",
       "  Document(metadata={'page': 10, 'author': '', 'moddate': '2008-07-11T11:25:03-07:00', 'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'total_pages': 16, 'creator': 'PScript5.dll Version 5.2.2', 'page_label': '11', 'source': 'docs/MachineLearning-Lecture03.pdf', 'creationdate': '2008-07-11T11:25:03-07:00', 'title': ''}, page_content='Instructor (Andrew Ng):Yeah, yeah. I mean, youâ€™re asking about overfitting, whether \\nthis is a good model. I think letâ€™s â€“ the thingâ€™s youâ€™re mentioning are maybe deeper \\nquestions about learning algorithms that weâ€™ll just come back to later, so donâ€™t really \\nwant to get into that right now. Any more questions? Okay.  \\nSo this endows linear regression with a probabilistic interpretation. Iâ€™m actually going to \\nuse this probabil â€“ use this, sort of, probabilistic interpretation in order to derive our next \\nlearning algorithm, which will be our first classification algorithm. Okay? So youâ€™ll recall \\nthat I said that regression problems are where the variable Y that youâ€™re trying to predict \\nis continuous values. Now Iâ€™m actually gonna talk about our first classification problem, \\nwhere the value Y youâ€™re trying to predict will be discreet value. You can take on only a \\nsmall number of discrete values and in this case Iâ€™ll talk about binding classification \\nwhere Y takes on only two values, right? So you come up with classification problems if \\nyouâ€™re trying to do, say, a medical diagnosis and try to decide based on some features that \\nthe patient has a disease or does not have a disease. Or if in the housing example, maybe \\nyouâ€™re trying to decide will this house sell in the next six months or not and the answer is \\neither yes or no. Itâ€™ll either be sold in the next six months or it wonâ€™t be. Other standing'),\n",
       "  Document(metadata={'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'title': '', 'creator': 'PScript5.dll Version 5.2.2', 'author': '', 'creationdate': '2008-07-11T11:25:23-07:00', 'source': 'docs/MachineLearning-Lecture01.pdf', 'total_pages': 22, 'page_label': '9', 'page': 8, 'moddate': '2008-07-11T11:25:23-07:00'}, page_content=\"statistics for a while or maybe algebra, we'll go over those in the discussion sections as a \\nrefresher for those of you that want one.  \\nLater in this quarter, we'll also use the discussion sections to go over extensions for the \\nmaterial that I'm teaching in the main lectures. So machine learning is a huge field, and \\nthere are a few extensions that we really want to teach but didn't have time in the main \\nlectures for.\"),\n",
       "  Document(metadata={'creationdate': '2008-07-11T11:25:03-07:00', 'source': 'docs/MachineLearning-Lecture03.pdf', 'page_label': '10', 'author': '', 'total_pages': 16, 'moddate': '2008-07-11T11:25:03-07:00', 'creator': 'PScript5.dll Version 5.2.2', 'title': '', 'page': 9, 'producer': 'Acrobat Distiller 8.1.0 (Windows)'}, page_content='come back to this again. Any questions about this? Actually, let me clean up another \\ncouple of boards and then Iâ€™ll see what questions you have.  \\nOkay. Any questions? Yeah?  \\nStudent:You are, I think here you try to measure the likelihood of your nice of theta by a \\nfraction of error, but I think itâ€™s that you measure because it depends on the family of \\ntheta too, for example. If you have a lot of parameters [inaudible] or fitting in?')]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74e2f6cc",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the context provided, probability is a topic covered in the class, as the instructor assumes familiarity with basic probability and statistics. Probability is used in the class to provide a probabilistic interpretation for linear regression and to derive the first classification algorithm. Thanks for asking!'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a2531ba",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'title': '', 'page': 4, 'page_label': '5', 'moddate': '2008-07-11T11:25:23-07:00', 'total_pages': 22, 'creator': 'PScript5.dll Version 5.2.2', 'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'source': 'docs/MachineLearning-Lecture01.pdf', 'creationdate': '2008-07-11T11:25:23-07:00', 'author': ''}, page_content=\"of this class will not be very programming intensive, although we will do some \\nprogramming, mostly in either MATLAB or Octave. I'll say a bit more about that later.  \\nI also assume familiarity with basic probability and statistics. So most undergraduate \\nstatistics class, like Stat 116 taught here at Stanford, will be more than enough. I'm gonna \\nassume all of you know what random variables are, that all of you know what expectation \\nis, what a variance or a random variable is. And in case of some of you, it's been a while \\nsince you've seen some of this material. At some of the discussion sections, we'll actually \\ngo over some of the prerequisites, sort of as a refresher course under prerequisite class. \\nI'll say a bit more about that later as well.  \\nLastly, I also assume familiarity with basic linear algebra. And again, most undergraduate \\nlinear algebra courses are more than enough. So if you've taken courses like Math 51, \\n103, Math 113 or CS205 at Stanford, that would be more than enough. Basically, I'm \\ngonna assume that all of you know what matrixes and vectors are, that you know how to \\nmultiply matrices and vectors and multiply matrix and matrices, that you know what a \\nmatrix inverse is. If you know what an eigenvector of a matrix is, that'd be even better. \\nBut if you don't quite know or if you're not quite sure, that's fine, too. We'll go over it in \\nthe review sections.\")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"source_documents\"][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience_course_cemfi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
